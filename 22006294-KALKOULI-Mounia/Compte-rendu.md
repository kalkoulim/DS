---

# ğŸ“˜ FOREST FIRES


![FIRE](FIRE.png)

---

## 1. Le Contexte MÃ©tier et la Mission

### Le ProblÃ¨me
Les feux de forÃªt causent des pertes Ã©conomiques et Ã©cologiques majeures, et menacent directement les populations et les infrastructures.â€‹
Objectif : prÃ©dire la surface brÃ»lÃ©e dâ€™un feu de forÃªt dans le parc de Montesinho (Portugal) Ã  partir de donnÃ©es mÃ©tÃ©o et dâ€™indices de sÃ©cheresse.

â€‹

Enjeu mÃ©tier :

Anticiper la gravitÃ© dâ€™un incendie pour adapter les moyens de prÃ©vention et de lutte (alerte, mobilisation des Ã©quipes, Ã©vacuation).

La â€œmauvaiseâ€ erreur nâ€™est pas symÃ©trique :

Sousâ€‘estimer une grande surface brÃ»lÃ©e (prÃ©dire petit alors que le feu sera grand) â†’ moyens insuffisants, dÃ©gÃ¢ts majeurs.

Surâ€‘estimer une surface (prÃ©dire grand pour un petit feu) â†’ surcoÃ»t opÃ©rationnel, mais risque humain plus faible.
        Dans ce contexte, on cherchera Ã  mieux prÃ©dire les grands feux et/ou Ã  rÃ©duire fortement les grosses sousâ€‘estimations (mÃ©triques de type RMSE, quantiles de lâ€™erreur, courbes REC comme dans Cortez & Morais)

### Les DonnÃ©es 
On utilise le dataset Forest Fires de lâ€™UCI Machine Learning Repository, 517 feux, 12 features + 1 cible area.

â€‹

X (features) :

Spatiales : X, Y (coordonnÃ©es sur la carte du parc, 1â€“9).

â€‹

Temporelles : month (janâ€“dec), day (monâ€“sun).

â€‹

Indices FWI : FFMC, DMC, DC, ISI (indices de sÃ©cheresse / inflammabilitÃ©).

â€‹

MÃ©tÃ©o directe : temp (Â°C), RH (% humiditÃ©), wind (km/h), rain (mm/mÂ²).
â€‹y (target) :

area : surface brÃ»lÃ©e en hectares, de 0 Ã  ~1090 ha, trÃ¨s fortement concentrÃ©e prÃ¨s de 0 (beaucoup de petits feux).

â€‹

Dans lâ€™article original, ln(area + 1) est utilisÃ© pour rendre le problÃ¨me de rÃ©gression plus stable.

---

## 2. Le Code Python (Laboratoire)

Ce script est votre paillasse de laboratoire. Il contient toutes les manipulations nÃ©cessaires.

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error

sns.set_theme(style="whitegrid")
import warnings
warnings.filterwarnings("ignore")

# --- PHASE 1 : ACQUISITION ---
url = "https://archive.ics.uci.edu/ml/machine-learning-databases/forest-fires/forestfires.csv"
df = pd.read_csv(url)

# --- PHASE 2 : DATA WRANGLING ---
# Pas de valeurs manquantes selon la description UCI
# Transformation de la cible (comme dans Cortez & Morais 2007)
df["area_log"] = np.log(df["area"] + 1)

X = df.drop(columns=["area", "area_log"])
y = df["area_log"]

num_cols = ["X", "Y", "FFMC", "DMC", "DC", "ISI", "temp", "RH", "wind", "rain"]
cat_cols = ["month", "day"]

preprocess = ColumnTransformer(
    transformers=[
        ("num", "passthrough", num_cols),
        ("cat", OneHotEncoder(drop="first"), cat_cols),
    ]
)

# --- PHASE 3 : EDA lÃ©gÃ¨re ---
print("--- AperÃ§u ---")
print(df.head())
print("\n--- Statistiques area ---")
print(df["area"].describe())

plt.figure(figsize=(6, 4))
sns.histplot(df["area"], bins=50)
plt.title("Distribution de la surface brÃ»lÃ©e (ha)")
plt.show()

plt.figure(figsize=(6, 4))
sns.histplot(df["area_log"], bins=50)
plt.title("Distribution de ln(area + 1)")
plt.show()

# --- PHASE 4 : PROTOCOLE EXPÃ‰RIMENTAL ---
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# --- PHASE 5 : MODELE (Random Forest) ---
model = RandomForestRegressor(
    n_estimators=300,
    random_state=42,
    n_jobs=-1
)

pipe = Pipeline(steps=[
    ("prep", preprocess),
    ("rf", model)
])

pipe.fit(X_train, y_train)

# --- PHASE 6 : EVALUATION ---
y_pred_log = pipe.predict(X_test)
# Retour Ã  lâ€™Ã©chelle originale
y_test_area = np.expm1(y_test)
y_pred_area = np.expm1(y_pred_log)

mae = mean_absolute_error(y_test_area, y_pred_area)
rmse = mean_squared_error(y_test_area, y_pred_area, squared=False)

print(f"\nMAE (ha) : {mae:.2f}")
print(f"RMSE (ha) : {rmse:.2f}")

plt.figure(figsize=(6, 5))
sns.scatterplot(x=y_test_area, y=y_pred_area)
plt.plot([0, max(y_test_area)], [0, max(y_test_area)], "r--")
plt.xlabel("Surface rÃ©elle (ha)")
plt.ylabel("Surface prÃ©dite (ha)")
plt.title("RÃ©elle vs prÃ©dite (Ã©chelle originale)")
plt.show()

 
```

---

## 3. Analyse Approfondie : Nettoyage (Data Wrangling)

Valeurs manquantes et qualitÃ© des donnÃ©es

La documentation UCI indique aucune valeur manquante sur ce dataset.

â€‹

En pratique, on vÃ©rifie quand mÃªme (df.isna().sum()) et la prÃ©sence de quelques doublons possibles.

    â€‹

Cible transformÃ©e : ln(area + 1)

area est ultraâ€‘skewÃ©e : la plupart des feux brÃ»lent moins de 1 ha, quelques cas extrÃªmes dÃ©passent 500 ha.

â€‹

La transformation lnâ¡(area+1)ln(area+1) :

Compresse les gros feux (rÃ©duit le poids des extrÃªmes).

Rapproche la distribution dâ€™une forme plus â€œgaussienneâ€, ce qui stabilise de nombreux modÃ¨les.

    â€‹

Comme dans le guide mÃ©dical, il faut penser Ã  lâ€™Ã©chelle de la cible : ici, les mÃ©triques finales doivent Ãªtre interprÃ©tÃ©es en hectares
(dâ€™oÃ¹ la reâ€‘transformation avec expm1).

    â€‹

Encodage des variables catÃ©gorielles

month et day sont nominales (pas ordinales strictement dans cette formulation UCI), on utilise donc Oneâ€‘Hot Encoding.

â€‹

Attention au data leakage : lâ€™encodeur est appris dans le Pipeline, donc uniquement sur le train, puis appliquÃ© au test, ce qui Ã©vite de â€œvoir le futurâ€. (MÃªme principe que pour lâ€™imputation dans ton guide initial, mais appliquÃ© Ã  lâ€™encodage.)


---

## 4. Analyse Approfondie : Exploration (EDA)

Distribution & skewness

Histogrammes de area et area_log :

area â†’ massivement concentrÃ©e sur 0 avec quelques valeurs Ã©normes.

â€‹

area_log â†’ plus â€œlisseâ€, plus exploitable par des modÃ¨les linÃ©aires ou des mÃ©triques classiques.

        â€‹

Relations avec les features

Quelques axes dâ€™exploration typiques :

â€‹
Saison / mois :

Plus de feux en Ã©tÃ© (juilâ€“sep), liÃ© Ã  temp Ã©levÃ©e, RH faible, DC et ISI Ã©levÃ©s.

MÃ©tÃ©o directe :

temp : les feux importants sont plus probables Ã  tempÃ©ratures Ã©levÃ©es.

rain : souvent 0 au moment de lâ€™incident, les grandes surfaces brÃ»lÃ©es surviennent en absence de pluie.

Indices FWI :

DC (sÃ©cheresse Ã  long terme) et ISI (vitesse de propagation) ont tendance Ã  Ãªtre plus Ã©levÃ©s pour les feux plus importants.

---

## 5. Analyse Approfondie : MÃ©thodologie (Split)

Objectif : gÃ©nÃ©ralisation vs surapprentissage

On cherche un modÃ¨le qui donne une bonne prÃ©cision moyenne, mais surtout qui ne sousâ€‘estime pas de faÃ§on catastrophique certains grands feux.

â€‹

Split classique : train_test_split(test_size=0.2, random_state=42) (80/20).

PossibilitÃ©s dâ€™aller plus loin :

kâ€‘fold crossâ€‘validation (ex : 10 folds) pour stabiliser les mesures Ã©tant donnÃ© la petite taille du dataset (517 lignes).

â€‹

RÃ©pÃ©ter les splits (comme Cortez & Morais : 10â€‘fold Ã— 30 runs) pour mieux Ã©valuer la robustesse du modÃ¨le

---

## 6. FOCUS THÃ‰ORIQUE : L'Algorithme Random Forest ğŸŒ²

La logique gÃ©nÃ©rale est la mÃªme que dans ton exemple mÃ©dical, mais appliquÃ©e Ã  une cible continue.

â€‹

Chaque arbre de dÃ©cision apprend une fonction â€œif/elseâ€ qui prÃ©dÃ®t une surface brÃ»lÃ©e Ã  partir des features (par exemple, si DC > seuil et ISI > seuil alors feu plus grand).

Le bagging + alÃ©a sur les features :

Bootstrap sur les lignes â†’ arbres variÃ©s.

Sousâ€‘ensemble alÃ©atoire de variables considÃ©rÃ©es Ã  chaque split â†’ explore diffÃ©rentes combinaisons mÃ©tÃ©o/spatiales.

        â€‹

En sortie, pour un nouvel incident :

Chaque arbre donne une prÃ©diction numÃ©rique (surface logâ€‘transformÃ©e).

La Random Forest moyenne ces valeurs pour donner la prÃ©diction finale (puis on applique expm1).

Sur ce dataset, des travaux montrent que RF est compÃ©titif mais que dâ€™autres modÃ¨les (SVM gaussien sur ln(area+1) par exemple) peuvent mieux capturer les petits feux, qui sont majoritaires
---

## 7. Analyse Approfondie : Ã‰valuation (L'Heure de VÃ©ritÃ©)

Pour un problÃ¨me de rÃ©gression, la â€œmatrice de confusionâ€ nâ€™existe pas, mais la logique mÃ©tier reste la mÃªme : punir plus sÃ©vÃ¨rement les grosses erreurs sur les grands feux.

â€‹
MÃ©triques de base

MAE (Mean Absolute Error) en hectares â†’ erreur moyenne absolue sur la surface brÃ»lÃ©e.

RMSE (Root Mean Squared Error) en hectares â†’ pÃ©nalise davantage les grandes erreurs (sousâ€‘estimations ou surâ€‘estimations massives).

MÃ©triques plus fines (dans lâ€™esprit de Cortez & Morais)

REC curve (Regression Error Characteristic) : pour un seuil dâ€™erreur E donnÃ© (par ex. 10 ha), on mesure la proportion de feux prÃ©dits avec une erreur â‰¤ E.

â€‹

Permet de dire : â€œDans X% des cas, lâ€™erreur est infÃ©rieure Ã  10 ha.â€

Analyse sÃ©parÃ©e des petits feux (area < 1 ha) vs grands feux (area > 50 ha, seuil Ã  dÃ©finir) pour vÃ©rifier que le modÃ¨le nâ€™ignore pas les cas rares mais critiques

### Conclusion du Projet
Le projet complet consiste donc Ã  :

Comprendre lâ€™enjeu : prioriser la bonne allocation des moyens de lutte, donc limiter les grosses sousâ€‘estimations des grands feux.

Construire une pipeline propre (encodage, transformation log, modÃ¨le, crossâ€‘validation).

Choisir des mÃ©triques adaptÃ©es (MAE/RMSE sur lâ€™Ã©chelle ha, REC, analyse des grands feux) et non se limiter Ã  un score unique.

Câ€™est la mÃªme â€œanatomieâ€ de projet que dans ton exemple mÃ©dical, mais transposÃ©e Ã  un problÃ¨me de rÃ©gression environnementale plutÃ´t quâ€™Ã  un problÃ¨me de classification mÃ©dicale.
